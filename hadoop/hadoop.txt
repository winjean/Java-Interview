name:root - winjean
name:winjean - winjean

vsftpd home:/etc/vsftpd
vsftpd user
		ftpuser1 - ftpuser1 路径/var/ftp/user1
		ftpuser2 - ftpuser2 路径/var/ftp/user2
		
 rpm -ivh jdk-6u11-linux-i586-rpm		
		

卸载已有java	
rpm -qa |grep jdk	
rpm -e --nodeps jdk-1.7.0_79-fcs.x86_64

安装java
rpm -ivh jdk-7u79-linux-x64.rpm

配置java环境
vi /etc/profile
export JAVA_HOME=/usr/java/jdk1.7.0_79
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar

需要修改的文件
~/hadoop/etc/hadoop/hadoop-env.sh
~/hadoop/etc/hadoop/yarn-env.sh
~/hadoop/etc/hadoop/slaves
~/hadoop/etc/hadoop/core-site.xml
~/hadoop/etc/hadoop/hdfs-site.xml
~/hadoop/etc/hadoop/mapred-site.xml
~/hadoop/etc/hadoop/yarn-site.xml

启动hdfs
./sbin/start-dfs.sh

启动yarn
./sbin/start-yarn.sh

启动datanode
./sbin/hadoop-daemon.sh start datanode

查看集群状态：
 ./bin/hdfs dfsadmin -report

查看hadoop
http://192.168.186.128:50070/

http://192.168.186.128:8088/

运行wordcount程序
1、创建 input目录：[spark@S1PA11 hadoop-2.6.0]$ mkdir input
2、在input创建f1、f2并写内容
 cat input/f1 
Hello world  bye jj
cat input/f2
Hello Hadoop  bye Hadoop
3、在hdfs创建/tmp/input目录
 ./bin/hadoop fs  -mkdir /tmp
 ./bin/hadoop fs  -mkdir /tmp/input
4、将f1、f2文件copy到hdfs /tmp/input目录
 ./bin/hadoop fs  -put input/ /tmp
5、查看hdfs上是否有f1、f2文件
 ./bin/hadoop fs -ls /tmp/input/
Found 2 items
-rw-r--r--   3 spark supergroup         20 2015-01-04 19:09 /tmp/input/f1
-rw-r--r--   3 spark supergroup         25 2015-01-04 19:09 /tmp/input/f2
6、执行wordcount程序
 ./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.1.jar wordcount /tmp/input /output
7、查看执行wordcount结果
 ./bin/hdfs dfs -cat /output/*
 
 eclipse Map/Reduce Location
 MR Master和DFS Master配置必须和mapred-site.xml和core-site.xml等配置文件一致